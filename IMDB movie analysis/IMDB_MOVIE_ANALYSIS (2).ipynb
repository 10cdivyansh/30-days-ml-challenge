{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xpA8Zbztr1Y",
        "outputId": "2a8fb30f-ef1e-4fd7-ceaa-fa04ff04c03c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ktrain\n",
            "  Downloading ktrain-0.35.1.tar.gz (25.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from ktrain) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from ktrain) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from ktrain) (1.4.4)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.9/dist-packages (from ktrain) (1.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from ktrain) (2.27.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from ktrain) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from ktrain) (23.0)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 KB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.9/dist-packages (from ktrain) (0.42.1)\n",
            "Collecting cchardet\n",
            "  Downloading cchardet-2.1.7-cp39-cp39-manylinux2010_x86_64.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.4/265.4 KB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.9/dist-packages (from ktrain) (4.0.0)\n",
            "Collecting syntok>1.3.3\n",
            "  Downloading syntok-1.4.4-py3-none-any.whl (24 kB)\n",
            "Collecting tika\n",
            "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers>=4.17.0\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras_bert>=0.86.0\n",
            "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting whoosh\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.8/468.8 KB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from keras_bert>=0.86.0->ktrain) (1.22.4)\n",
            "Collecting keras-transformer==0.40.0\n",
            "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-pos-embd==0.13.0\n",
            "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-multi-head==0.29.0\n",
            "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-layer-normalization==0.16.0\n",
            "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-position-wise-feed-forward==0.8.0\n",
            "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-embed-sim==0.10.0\n",
            "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-self-attention==0.51.0\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (4.39.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (1.0.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (8.4.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (5.12.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.1->ktrain) (2022.7.1)\n",
            "Requirement already satisfied: regex>2016 in /usr/local/lib/python3.9/dist-packages (from syntok>1.3.3->ktrain) (2022.10.31)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.17.0->ktrain) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.17.0->ktrain) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers>=4.17.0->ktrain) (3.10.7)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from langdetect->ktrain) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->ktrain) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->ktrain) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->ktrain) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->ktrain) (1.26.15)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->ktrain) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->ktrain) (1.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tika->ktrain) (67.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=4.17.0->ktrain) (4.5.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.0.0->ktrain) (3.15.0)\n",
            "Building wheels for collected packages: ktrain, keras_bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, langdetect, tika\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.35.1-py3-none-any.whl size=25316191 sha256=505c88a3425ad29448ba4d82b2483efb4ced0fde3d476e049b6104edd33e11a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/86/fe/b944ff9fb89c0ce9aab68e7a0c5d53c98c52ae0326fe0942ca\n",
            "  Building wheel for keras_bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33517 sha256=c149f627f82e3ea45d9aa751963ff6af7c9e7c8f9205f3c51e84435f663df6d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/26/24/14ecbc0166364db7f5500164b7d796263cf3cd10c57e892180\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12303 sha256=5f08a835e05017ee2a39eff35c1df30b2e9b0fba085da0986eff868ef82c6528\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/d6/d1/c588c3b2b112c8f1173934995836ab2f2de8323cce99fa998f\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3959 sha256=a91c920f1840d0e8f9187123c0303808af5ce2a9ce4b720f37d206c1ba299817\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/25/02/4bb438785ef9c10d07f6b3519f080b38917153fdac3108d738\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4666 sha256=a3a9ccdb118edc7fa791b9fb5ab5119f3090af162a380c302cc7200464bf9de8\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/df/15/a88cdf68ce687574649f65063a743123e1bee79932b6eea3b6\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14992 sha256=e1cf5d49d087727bc2caa0e41e402e9c7b7e08cd5dddc3209ff5c500b4cb8521\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/85/50/f232cac81ed1eb4dc20db31a9d1f4a8a1a8c696d4d27bff442\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6958 sha256=2c8369d48cdf5686eb6f99569b5ca68adca99eda4d01a6a58a7874f636787440\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/8c/9a/917bf72d493e084ca1706a02679185789c2715f50770d8c987\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4983 sha256=bcf6383ae2b9dd7413e7f55ce6591ed0708832d5d933672e51fd3074759d029b\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/36/25/efb605ab1742a179274a6f7cb113da1c6758f45e212b59bb4d\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18910 sha256=b7bf96a11983151b7478bbef67c7adc4273944cf84f67df64c66211abbfe4eee\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/c1/84/b83a2fd6f1d63e136cba74bac4126bee3b8705eef6486635fd\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993243 sha256=6e781a7b77904d1e80e7bb368d604981285ab57838c6145a36e41ce676c6a070\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/c1/d9/7e068de779d863bc8f8fc9467d85e25cfe47fa5051fff1a1bb\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32641 sha256=cfa265a533aa9bd0e53a8d92ab6352b9f79f1a627a3fc2885f077137586a0249\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/56/18/e752060632d32c39c9c4545e756dad281f8504dafcfac02b95\n",
            "Successfully built ktrain keras_bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention langdetect tika\n",
            "Installing collected packages: whoosh, tokenizers, sentencepiece, cchardet, syntok, langdetect, keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-layer-normalization, keras-embed-sim, tika, keras-multi-head, huggingface-hub, transformers, keras-transformer, keras_bert, ktrain\n",
            "Successfully installed cchardet-2.1.7 huggingface-hub-0.13.3 keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 keras_bert-0.89.0 ktrain-0.35.1 langdetect-1.0.9 sentencepiece-0.1.97 syntok-1.4.4 tika-2.6.0 tokenizers-0.13.3 transformers-4.27.4 whoosh-2.7.4\n"
          ]
        }
      ],
      "source": [
        "!pip3 install ktrain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEib5Jp4t29O",
        "outputId": "9a9be8f4-7455-48b0-f51c-c1438dccc7b1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 5, in <module>\n",
            "    from pip._internal.cli.main import main\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/cli/main.py\", line 9, in <module>\n",
            "    from pip._internal.cli.autocompletion import autocomplete\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
            "    from pip._internal.cli.main_parser import create_main_parser\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/cli/main_parser.py\", line 8, in <module>\n",
            "    from pip._internal.cli import cmdoptions\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/cli/cmdoptions.py\", line 23, in <module>\n",
            "    from pip._internal.cli.parser import ConfigOptionParser\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/cli/parser.py\", line 12, in <module>\n",
            "    from pip._internal.configuration import Configuration, ConfigurationError\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/configuration.py\", line 20, in <module>\n",
            "    from pip._internal.exceptions import (\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/exceptions.py\", line 14, in <module>\n",
            "    from pip._vendor.rich.console import Console, ConsoleOptions, RenderResult\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pip/_vendor/rich/console.py\", line 55, in <module>\n",
            "    from .pretty import Pretty, is_expandable\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pip/_vendor/rich/pretty.py\", line 450, in <module>\n",
            "    class _Line:\n",
            "  File \"/usr/lib/python3.9/dataclasses.py\", line 1021, in dataclass\n",
            "    return wrap(cls)\n",
            "  File \"/usr/lib/python3.9/dataclasses.py\", line 1013, in wrap\n",
            "    return _process_class(cls, init, repr, eq, order, unsafe_hash, frozen)\n",
            "  File \"/usr/lib/python3.9/dataclasses.py\", line 927, in _process_class\n",
            "    _init_fn(flds,\n",
            "  File \"/usr/lib/python3.9/dataclasses.py\", line 531, in _init_fn\n",
            "    return _create_fn('__init__',\n",
            "  File \"/usr/lib/python3.9/dataclasses.py\", line 400, in _create_fn\n",
            "    exec(txt, globals, ns)\n",
            "  File \"<string>\", line 1, in <module>\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cpyv_sGDAqcK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import ktrain\n",
        "from ktrain import text"
      ],
      "metadata": {
        "id": "-y3ntIbRt6ov"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.keras.utils.get_file(fname=\"aclImdb_v1.tar.gz\",origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",extract=True)\n",
        "IMDB_DATADIR = os.path.join(os.path.dirname(dataset), 'aclImdb')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qylpzLVLt9c3",
        "outputId": "0d0d459a-60e4-4066-8403-f54b6c27c1b9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84125825/84125825 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.path.dirname(dataset))\n",
        "print(IMDB_DATADIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-bKAWlGt9hH",
        "outputId": "48883fe8-805d-41b5-8a4c-855e5ac21350"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.keras/datasets\n",
            "/root/.keras/datasets/aclImdb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test), preproc = text.texts_from_folder(datadir=IMDB_DATADIR,classes=['pos','neg'],maxlen=500,train_test_names=['train','test'],preprocess_mode='bert')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "pBN9sLVBuFmX",
        "outputId": "701c9dcf-b5f3-4ba6-d56b-36d38281e519"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "detected encoding: utf-8\n",
            "downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n",
            "[██████████████████████████████████████████████████]\n",
            "extracting pretrained BERT model...\n",
            "done.\n",
            "\n",
            "cleanup downloaded zip...\n",
            "done.\n",
            "\n",
            "preprocessing train...\n",
            "language: en\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "done."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "done."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=text.text_classifier(name=\"bert\",train_data=(x_train, y_train),preproc=preproc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_h_OQsVuFzn",
        "outputId": "0e762028-a611-4a02-8631-11124c7caea1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learner=ktrain.get_learner(model=model,train_data=(x_train, y_train),val_data=(x_test, y_test),batch_size=6)"
      ],
      "metadata": {
        "id": "uX9zWEwauF2n"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learner.fit_onecycle(lr=2e-5,epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tnkJ085uPDA",
        "outputId": "7fd1241d-4ea6-42e7-b8b6-50310c11ad66"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "4167/4167 [==============================] - 4952s 1s/step - loss: 0.2617 - accuracy: 0.8916 - val_loss: 0.1686 - val_accuracy: 0.9353\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc639fb7a00>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_bert = [x_train, np.ones((len(x_train), 500), dtype=int)]\n",
        "x_test_bert = [x_test, np.ones((len(x_test), 500), dtype=int)]\n",
        "y_pred = learner.predict(x_test_bert)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_true = y_test.argmax(axis=1)\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print('Accuracy:', accuracy)\n",
        "\n",
        "print(classification_report(y_true, y_pred))\n"
      ],
      "metadata": {
        "id": "21eXKd1mvFsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae6fcc6-d6f6-4d11-a6e2-39297cad6886"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 1209s 2s/step\n",
            "Accuracy: 0.93532\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.94      0.94     12500\n",
            "           1       0.94      0.93      0.94     12500\n",
            "\n",
            "    accuracy                           0.94     25000\n",
            "   macro avg       0.94      0.94      0.94     25000\n",
            "weighted avg       0.94      0.94      0.94     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qx1XKIBcSacK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}